{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9311912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "churn= pd.read_csv(f\"final_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2457769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churn.drop('Exited', axis=1)\n",
    "y = churn['Exited']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "158f6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315d4bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      1593\n",
      "           1       0.57      0.17      0.26       404\n",
      "\n",
      "    accuracy                           0.81      1997\n",
      "   macro avg       0.70      0.57      0.57      1997\n",
      "weighted avg       0.77      0.81      0.76      1997\n",
      "\n",
      "ROC-AUC: 0.76607279372005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"ðŸ”¹ Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, log_reg.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528ef736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1593\n",
      "           1       0.77      0.45      0.57       404\n",
      "\n",
      "    accuracy                           0.86      1997\n",
      "   macro avg       0.82      0.71      0.74      1997\n",
      "weighted avg       0.85      0.86      0.85      1997\n",
      "\n",
      "ROC-AUC: 0.8511899212520122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"ðŸ”¹ Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06e2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1593\n",
      "           1       0.68      0.49      0.57       404\n",
      "\n",
      "    accuracy                           0.85      1997\n",
      "   macro avg       0.78      0.72      0.74      1997\n",
      "weighted avg       0.84      0.85      0.84      1997\n",
      "\n",
      "ROC-AUC: 0.841598142865134\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"ðŸ”¹ XGBoost Results:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, xgb.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d303481",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Exited\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_curve, roc_auc_score\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get predicted probabilities for the positive class (churn = 1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m y_proba_lr = \u001b[43mlog_reg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[32m1\u001b[39m]\n\u001b[32m      6\u001b[39m y_proba_rf = rf.predict_proba(X_test)[:,\u001b[32m1\u001b[39m]\n\u001b[32m      7\u001b[39m y_proba_xgb = xgb.predict_proba(X_test)[:,\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ENVY\\OneDrive\\Desktop\\Financial_Risk_and_Customer_Retention\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1462\u001b[39m, in \u001b[36mLogisticRegression.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1457\u001b[39m ovr = \u001b[38;5;28mself\u001b[39m.multi_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33movr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1458\u001b[39m     \u001b[38;5;28mself\u001b[39m.multi_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdeprecated\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1459\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.classes_.size <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.solver == \u001b[33m\"\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1460\u001b[39m )\n\u001b[32m   1461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     decision = \u001b[38;5;28mself\u001b[39m.decision_function(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ENVY\\OneDrive\\Desktop\\Financial_Risk_and_Customer_Retention\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:390\u001b[39m, in \u001b[36mLinearClassifierMixin._predict_proba_lr\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[32m    387\u001b[39m \u001b[33;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m     expit(prob, out=prob)\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prob.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ENVY\\OneDrive\\Desktop\\Financial_Risk_and_Customer_Retention\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:352\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    349\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    350\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m scores = safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    355\u001b[39m     xp.reshape(scores, (-\u001b[32m1\u001b[39m,))\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (scores.ndim > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[32m    358\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ENVY\\OneDrive\\Desktop\\Financial_Risk_and_Customer_Retention\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ENVY\\OneDrive\\Desktop\\Financial_Risk_and_Customer_Retention\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2787\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2785\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Exited\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Get predicted probabilities for the positive class (churn = 1)\n",
    "y_proba_lr = log_reg.predict_proba(X_test)[:,1]\n",
    "y_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "y_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute ROC curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_proba_xgb)\n",
    "\n",
    "# Compute AUC scores\n",
    "auc_lr = roc_auc_score(y_test, y_proba_lr)\n",
    "auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "auc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"Logistic Regression (AUC = {auc_lr:.3f})\", linewidth=2)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {auc_rf:.3f})\", linewidth=2)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f\"XGBoost (AUC = {auc_xgb:.3f})\", linewidth=2)\n",
    "\n",
    "# Reference line (no skill)\n",
    "plt.plot([0,1], [0,1], 'k--', label='No Skill', linewidth=1.5)\n",
    "\n",
    "# Formatting\n",
    "plt.title('ROC Curve Comparison for Churn Prediction', fontsize=13)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial-risk-and-customer-retention-py3.12 (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
